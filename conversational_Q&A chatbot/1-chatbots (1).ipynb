{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\", \"your_langchain_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\", \"your_langchain_project_here\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\", \"your_groq_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000021AE33CFAD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021AE363CDD0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Rehaman, it's nice to meet you! \\n\\nI'm glad to hear you're studying AI. It's a fascinating and rapidly evolving field. \\n\\nWhat aspects of AI are you most interested in? Perhaps we could discuss them further.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 30, 'total_tokens': 89, 'completion_time': 0.107272727, 'prompt_time': 0.002141025, 'queue_time': 0.24207731400000002, 'total_time': 0.109413752}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d6f14e08-87d1-4553-9611-497e5763f554-0', usage_metadata={'input_tokens': 30, 'output_tokens': 59, 'total_tokens': 89})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Rehaman and I am a  student studying in the field of AI.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Rehaman and that you are a student studying in the field of AI.  üòÑ \\n\\nIs there anything else you'd like to tell me about yourself or your studies?  I'm happy to chat!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 104, 'total_tokens': 157, 'completion_time': 0.096363636, 'prompt_time': 0.005542386, 'queue_time': 0.249957714, 'total_time': 0.101906022}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f9e13b5f-b89d-4645-9670-5b5ce0558a27-0', usage_metadata={'input_tokens': 104, 'output_tokens': 53, 'total_tokens': 157})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Rehaman and I am a  student studying in the field of AI.\"),\n",
    "        AIMessage(content=\"Hi Rehaman,\\n\\nIt's nice to meet you!\\n\\nAI is a fascinating field. What aspects of AI are you most interested in studying? \\n\\nI'm always eager to learn more about what people are doing in this space.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.61)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.42)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , i am a lawyer always filing cases on AI\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's interesting! As an AI, I can't provide legal advice, but I can offer some information that might be relevant to your work. \\n\\nWhat kind of cases are you filing? Are they related to:\\n\\n* **Bias in AI algorithms?**\\n* **Intellectual property rights of AI-generated content?**\\n* **Liability for AI-caused harm?**\\n* **Privacy concerns related to AI data collection?**\\n* **Regulation of AI development and deployment?**\\n\\nKnowing the specific area of AI law you're focusing on would allow me to provide more tailored and helpful information. \\n\\nFor example, I could share:\\n\\n* **Recent legal developments and case precedents**\\n* **Relevant legislation and regulations**\\n* **Ethical considerations in AI**\\n* **Resources for legal professionals specializing in AI**\\n\\n\\nLet me know how I can be of assistance!  \\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It sounds like you're interested in exploring the legal implications of AI. That's a fascinating and rapidly evolving field! \\n\\nSince I can't give legal advice, I can't tell you exactly *what* to do. But I can offer some ideas for how you could contribute to this area of law:\\n\\n**1. Specialize in AI Law:** \\n   - Deepen your knowledge of AI technologies and their legal implications. \\n   - Consider taking specialized courses or certifications in AI law.\\n   - Network with other lawyers and experts in the field.\\n\\n**2. Advocate for Ethical AI Development:**\\n   - Work with organizations promoting responsible AI development and use.\\n   - Lobby for legislation that protects against AI bias, discrimination, and misuse.\\n   - Educate the public about the potential benefits and risks of AI.\\n\\n**3. Represent Clients in AI-Related Disputes:**\\n   - Advise businesses on legal compliance related to AI systems.\\n   - Represent individuals harmed by AI-powered technologies.\\n   - Litigate cases involving intellectual property rights, data privacy, or liability issues related to AI.\\n\\n**4. Research and Publish on AI Law:**\\n   - Contribute to the academic and legal discourse on AI ethics and regulation.\\n   - Write articles, books, or legal analyses exploring emerging issues in AI law.\\n   - Present your research at conferences and workshops.\\n\\n**5. Develop AI-Related Legal Tools and Resources:**\\n   - Create online databases, guides, or templates for lawyers handling AI cases.\\n   - Design AI-powered legal tools to assist with contract review, risk assessment, or legal research related to AI. \\n\\nRemember, AI law is a dynamic field that requires continuous learning and adaptation. By staying informed and engaging with the community, you can make a meaningful contribution to shaping the future of AI and its impact on society. \\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 394, 'prompt_tokens': 219, 'total_tokens': 613, 'completion_time': 0.716363636, 'prompt_time': 0.025508627, 'queue_time': 0.249911461, 'total_time': 0.741872263}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--aa01cb16-2a17-48d1-a27a-5b5c8813b1b9-0', usage_metadata={'input_tokens': 219, 'output_tokens': 394, 'total_tokens': 613})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what i do ?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know!\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well hello there, Tom Cruise! It's a pleasure to meet you. \\n\\nIs there anything I can help you with today? Perhaps you'd like to discuss your latest movie, or maybe you want to explore some creative writing ideas?  üé¨  \\n\\nLet me know what's on your mind! üòÅ\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is Tom Cruise\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You told me your name is Tom Cruise!  \\n\\nIs there anything else I can help you with, Mr. Cruise? üòä  \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Rehaman! \\n\\nIt's nice to meet you. How can I help you today?  \\n\\nI'm ready for your questions! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 32, 'total_tokens': 70, 'completion_time': 0.069090909, 'prompt_time': 0.002354814, 'queue_time': 0.253378724, 'total_time': 0.071445723}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f32434cb-448b-49c1-8821-0aef72d69129-0', usage_metadata={'input_tokens': 32, 'output_tokens': 38, 'total_tokens': 70})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Rehaman\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Rehaman! It's nice to meet you.  üòä\\n\\nI'm happy to help with any questions you have. Just ask away!  What can I do for you today? \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 32, 'total_tokens': 77, 'completion_time': 0.081818182, 'prompt_time': 0.002537473, 'queue_time': 0.24323595599999998, 'total_time': 0.084355655}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ae15e1e1-868e-4e07-b2b8-b578f5cfe52a-0', usage_metadata={'input_tokens': 32, 'output_tokens': 45, 'total_tokens': 77})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Rehaman\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Rehaman.  I remember! üòä  How can I help you further?\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Rehaman! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§  üòä\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Rehaman\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Rehaman!  \\n\\n‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§ ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§ï‡•ã‡§ö ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§ \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Rehaman\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Rehaman ‡§π‡•à‡•§  üòä \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sk abdul rehaman\\onedrive\\desktop\\rehaman_resources\\codes\\agenticai_langchain\\venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:64\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\__init__.py:27\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     logging,\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\utils\\__init__.py:24\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01margs_doc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ClassAttrs,\n\u001b[32m     26\u001b[39m     ClassDocstring,\n\u001b[32m     27\u001b[39m     ImageProcessorArgs,\n\u001b[32m     28\u001b[39m     ModelArgs,\n\u001b[32m     29\u001b[39m     auto_class_docstring,\n\u001b[32m     30\u001b[39m     auto_docstring,\n\u001b[32m     31\u001b[39m     parse_docstring,\n\u001b[32m     32\u001b[39m     set_min_indent,\n\u001b[32m     33\u001b[39m     source_args_doc,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\utils\\args_doc.py:30\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     MODELS_TO_PIPELINE,\n\u001b[32m     26\u001b[39m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001b[32m     27\u001b[39m     PT_SAMPLE_DOCSTRINGS,\n\u001b[32m     28\u001b[39m     _prepare_output_docstrings,\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelOutput\n\u001b[32m     33\u001b[39m PATH_TO_TRANSFORMERS = Path(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m).resolve() / \u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:480\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_torch_pytree\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_model_output_flatten\u001b[39m(output: ModelOutput) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Any], \u001b[33m\"\u001b[39m\u001b[33m_torch_pytree.Context\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\torch\\utils\\__init__.py:8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     backcompat \u001b[38;5;28;01mas\u001b[39;00m backcompat,\n\u001b[32m     10\u001b[39m     collect_env \u001b[38;5;28;01mas\u001b[39;00m collect_env,\n\u001b[32m     11\u001b[39m     data \u001b[38;5;28;01mas\u001b[39;00m data,\n\u001b[32m     12\u001b[39m     deterministic \u001b[38;5;28;01mas\u001b[39;00m deterministic,\n\u001b[32m     13\u001b[39m     hooks \u001b[38;5;28;01mas\u001b[39;00m hooks,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     generate_methods_for_privateuse1_backend,\n\u001b[32m     17\u001b[39m     rename_privateuse1_backend,\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\torch\\utils\\backcompat\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _set_backcompat_broadcast_warn\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_backcompat_broadcast_warn\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch._C'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      2\u001b[39m trimmer=trim_messages(\n\u001b[32m      3\u001b[39m     max_tokens=\u001b[32m45\u001b[39m,\n\u001b[32m      4\u001b[39m     strategy=\u001b[33m\"\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     start_on=\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m messages = [\n\u001b[32m     11\u001b[39m     SystemMessage(content=\u001b[33m\"\u001b[39m\u001b[33myou\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre a good assistant\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     12\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mhi! I\u001b[39m\u001b[33m'\u001b[39m\u001b[33mm bob\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     AIMessage(content=\u001b[33m\"\u001b[39m\u001b[33myes!\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     22\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrimmer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4771\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4757\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4758\u001b[39m \n\u001b[32m   4759\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4768\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4769\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4772\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4773\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4775\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4776\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4777\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4778\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4629\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4627\u001b[39m                 output = chunk\n\u001b[32m   4628\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4629\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4630\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4632\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\messages\\utils.py:927\u001b[39m, in \u001b[36mtrim_messages\u001b[39m\u001b[34m(messages, max_tokens, token_counter, strategy, allow_partial, end_on, start_on, include_system, text_splitter)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _first_max_tokens(\n\u001b[32m    919\u001b[39m         messages,\n\u001b[32m    920\u001b[39m         max_tokens=max_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m    924\u001b[39m         end_on=end_on,\n\u001b[32m    925\u001b[39m     )\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strategy == \u001b[33m\"\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_max_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_counter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlist_token_counter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_system\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_system\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_splitter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_splitter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m. Supported strategies are \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\messages\\utils.py:1448\u001b[39m, in \u001b[36m_last_max_tokens\u001b[39m\u001b[34m(messages, max_tokens, token_counter, text_splitter, allow_partial, include_system, start_on, end_on)\u001b[39m\n\u001b[32m   1446\u001b[39m remaining_tokens = max_tokens\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m system_message:\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     system_tokens = \u001b[43mtoken_counter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     remaining_tokens = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, max_tokens - system_tokens)\n\u001b[32m   1451\u001b[39m reversed_result = _first_max_tokens(\n\u001b[32m   1452\u001b[39m     reversed_messages,\n\u001b[32m   1453\u001b[39m     max_tokens=remaining_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1457\u001b[39m     end_on=start_on,\n\u001b[32m   1458\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:393\u001b[39m, in \u001b[36mBaseLanguageModel.get_num_tokens_from_messages\u001b[39m\u001b[34m(self, messages, tools)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    389\u001b[39m     warnings.warn(\n\u001b[32m    390\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCounting tokens in tool schemas is not yet supported. Ignoring tools.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    391\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    392\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_buffer_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:393\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    389\u001b[39m     warnings.warn(\n\u001b[32m    390\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCounting tokens in tool schemas is not yet supported. Ignoring tools.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    391\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    392\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_buffer_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:366\u001b[39m, in \u001b[36mBaseLanguageModel.get_num_tokens\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_num_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the number of tokens present in the text.\u001b[39;00m\n\u001b[32m    357\u001b[39m \n\u001b[32m    358\u001b[39m \u001b[33;03m    Useful for checking if an input fits in a model's context window.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m \u001b[33;03m        The integer number of tokens in the text.\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:353\u001b[39m, in \u001b[36mBaseLanguageModel.get_token_ids\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.custom_get_token_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.custom_get_token_ids(text)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_token_ids_default_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:79\u001b[39m, in \u001b[36m_get_token_ids_default_method\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Encode the text into token IDs.\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# get the cached tokenizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m tokenizer = \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# tokenize the text using the GPT-2 tokenizer\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.encode(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:71\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     66\u001b[39m     msg = (\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis is needed in order to calculate get_token_ids. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# create a GPT-2 tokenizer instance\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m GPT2TokenizerFast.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mgpt2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`."
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:64\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\__init__.py:27\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     logging,\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\utils\\__init__.py:24\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01margs_doc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ClassAttrs,\n\u001b[32m     26\u001b[39m     ClassDocstring,\n\u001b[32m     27\u001b[39m     ImageProcessorArgs,\n\u001b[32m     28\u001b[39m     ModelArgs,\n\u001b[32m     29\u001b[39m     auto_class_docstring,\n\u001b[32m     30\u001b[39m     auto_docstring,\n\u001b[32m     31\u001b[39m     parse_docstring,\n\u001b[32m     32\u001b[39m     set_min_indent,\n\u001b[32m     33\u001b[39m     source_args_doc,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\utils\\args_doc.py:30\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     MODELS_TO_PIPELINE,\n\u001b[32m     26\u001b[39m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001b[32m     27\u001b[39m     PT_SAMPLE_DOCSTRINGS,\n\u001b[32m     28\u001b[39m     _prepare_output_docstrings,\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelOutput\n\u001b[32m     33\u001b[39m PATH_TO_TRANSFORMERS = Path(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m).resolve() / \u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:480\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_torch_pytree\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_model_output_flatten\u001b[39m(output: ModelOutput) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Any], \u001b[33m\"\u001b[39m\u001b[33m_torch_pytree.Context\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\torch\\utils\\__init__.py:8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     backcompat \u001b[38;5;28;01mas\u001b[39;00m backcompat,\n\u001b[32m     10\u001b[39m     collect_env \u001b[38;5;28;01mas\u001b[39;00m collect_env,\n\u001b[32m     11\u001b[39m     data \u001b[38;5;28;01mas\u001b[39;00m data,\n\u001b[32m     12\u001b[39m     deterministic \u001b[38;5;28;01mas\u001b[39;00m deterministic,\n\u001b[32m     13\u001b[39m     hooks \u001b[38;5;28;01mas\u001b[39;00m hooks,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     generate_methods_for_privateuse1_backend,\n\u001b[32m     17\u001b[39m     rename_privateuse1_backend,\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\torch\\utils\\backcompat\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _set_backcompat_broadcast_warn\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_backcompat_broadcast_warn\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch._C'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough\n\u001b[32m      5\u001b[39m chain=(\n\u001b[32m      6\u001b[39m     RunnablePassthrough.assign(messages=itemgetter(\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m)|trimmer)\n\u001b[32m      7\u001b[39m     | prompt\n\u001b[32m      8\u001b[39m     | model\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response=\u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat ice cream do i like\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlanguage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnglish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3045\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3044\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3045\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3047\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:511\u001b[39m, in \u001b[36mRunnableAssign.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m     **kwargs: Any,\n\u001b[32m    510\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:497\u001b[39m, in \u001b[36mRunnableAssign._invoke\u001b[39m\u001b[34m(self, value, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m    492\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    496\u001b[39m     **value,\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    502\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3774\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3769\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3770\u001b[39m         futures = [\n\u001b[32m   3771\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3772\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3773\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3774\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3775\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3776\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3758\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3752\u001b[39m child_config = patch_config(\n\u001b[32m   3753\u001b[39m     config,\n\u001b[32m   3754\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3755\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3756\u001b[39m )\n\u001b[32m   3757\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3759\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3760\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3761\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3762\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4771\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4757\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4758\u001b[39m \n\u001b[32m   4759\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4768\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4769\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4772\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4773\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4775\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4776\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4777\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4778\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4629\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4627\u001b[39m                 output = chunk\n\u001b[32m   4628\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4629\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4630\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4632\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\messages\\utils.py:927\u001b[39m, in \u001b[36mtrim_messages\u001b[39m\u001b[34m(messages, max_tokens, token_counter, strategy, allow_partial, end_on, start_on, include_system, text_splitter)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _first_max_tokens(\n\u001b[32m    919\u001b[39m         messages,\n\u001b[32m    920\u001b[39m         max_tokens=max_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m    924\u001b[39m         end_on=end_on,\n\u001b[32m    925\u001b[39m     )\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strategy == \u001b[33m\"\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_max_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_counter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlist_token_counter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_system\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_system\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_splitter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_splitter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m. Supported strategies are \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\messages\\utils.py:1448\u001b[39m, in \u001b[36m_last_max_tokens\u001b[39m\u001b[34m(messages, max_tokens, token_counter, text_splitter, allow_partial, include_system, start_on, end_on)\u001b[39m\n\u001b[32m   1446\u001b[39m remaining_tokens = max_tokens\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m system_message:\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     system_tokens = \u001b[43mtoken_counter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     remaining_tokens = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, max_tokens - system_tokens)\n\u001b[32m   1451\u001b[39m reversed_result = _first_max_tokens(\n\u001b[32m   1452\u001b[39m     reversed_messages,\n\u001b[32m   1453\u001b[39m     max_tokens=remaining_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1457\u001b[39m     end_on=start_on,\n\u001b[32m   1458\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:393\u001b[39m, in \u001b[36mBaseLanguageModel.get_num_tokens_from_messages\u001b[39m\u001b[34m(self, messages, tools)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    389\u001b[39m     warnings.warn(\n\u001b[32m    390\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCounting tokens in tool schemas is not yet supported. Ignoring tools.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    391\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    392\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_buffer_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:393\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    389\u001b[39m     warnings.warn(\n\u001b[32m    390\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCounting tokens in tool schemas is not yet supported. Ignoring tools.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    391\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    392\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_buffer_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:366\u001b[39m, in \u001b[36mBaseLanguageModel.get_num_tokens\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_num_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the number of tokens present in the text.\u001b[39;00m\n\u001b[32m    357\u001b[39m \n\u001b[32m    358\u001b[39m \u001b[33;03m    Useful for checking if an input fits in a model's context window.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m \u001b[33;03m        The integer number of tokens in the text.\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:353\u001b[39m, in \u001b[36mBaseLanguageModel.get_token_ids\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.custom_get_token_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.custom_get_token_ids(text)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_token_ids_default_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:79\u001b[39m, in \u001b[36m_get_token_ids_default_method\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Encode the text into token IDs.\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# get the cached tokenizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m tokenizer = \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# tokenize the text using the GPT-2 tokenizer\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.encode(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI_langchain\\venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:71\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     66\u001b[39m     msg = (\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis is needed in order to calculate get_token_ids. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# create a GPT-2 tokenizer instance\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m GPT2TokenizerFast.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mgpt2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`."
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"whats 2 + 2\" üòä  \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the MEssage History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I don't have access to past conversations or any personal information about you, including your name.  \\n\\nIf you'd like to tell me your name, I'd be happy to know! üòä  \\n\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations. If you'd like to ask me a math problem, I'm happy to help! üòä  Just let me know what it is. \\n\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
